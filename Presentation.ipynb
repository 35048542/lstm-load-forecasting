{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Presentation of the LSTM ANN model\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0ebd045fb39448f94484afc96ec7aeb"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2e05a78e12e41519f26fa4cbf135738"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# module imports\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import datetime\n",
    "from datetime import date\n",
    "import itertools\n",
    "import time as t\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "from statsmodels.tsa import stattools\n",
    "from tabulate import tabulate\n",
    "\n",
    "import math\n",
    "import keras as keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, Dense, Dropout, LSTM\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.utils import np_utils\n",
    "from keras.models import load_model\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "from IPython.display import HTML\n",
    "from IPython.display import display\n",
    "\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# Import custom module functions\n",
    "module_path = os.path.abspath(os.path.join(''))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from lstm_load_forecasting import data, lstm\n",
    "\n",
    "from ast import literal_eval\n",
    "\n",
    "from dateutil.tz import tzutc\n",
    "\n",
    "import pytz\n",
    "\n",
    "modules = widgets.ToggleButtons(\n",
    "    options={'ENTSO-E FC Only':['entsoe'], 'Calendar Only':['calendar'], 'Weather only':['weather'], 'Calendar + Weather':['calendar', 'weather'], 'All':['all']},\n",
    "    description='Choose data:',\n",
    "    disabled=False,\n",
    "    button_style='info', # 'success', 'info', 'warning', 'danger' or ''\n",
    "    tooltip='Choose the data module that the model should be run with',\n",
    ")\n",
    "update_date = widgets.DatePicker(description='Update date')\n",
    "display(modules, update_date)\n",
    "path = os.path.join(os.path.abspath(''), 'Data/fulldataset.csv')\n",
    "\n",
    "sel_mod = modules.value\n",
    "sel_mod.append('actual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.load_dataset(path=path, modules=['all'], update_date = update_date.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Options "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "timezone = pytz.timezone('Europe/Zurich')\n",
    "starting = timezone.localize(datetime.datetime(2017,5,15,0,0,0,0))\n",
    "path = os.path.join('Data', 'fulldataset.csv')\n",
    "res_path = os.path.abspath('results/')\n",
    "model_dir = os.path.abspath('models/')\n",
    "date = '20170508'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df\n",
    "df3_scaled = df3.copy()\n",
    "df3_scaled = df3_scaled.dropna()\n",
    "\n",
    "# Get all float type columns\n",
    "floats = [key for key in dict(df3_scaled.dtypes) if dict(df3_scaled.dtypes)[key] in ['float64']]\n",
    "scaler = StandardScaler()\n",
    "scaled_columns = scaler.fit_transform(df3_scaled[floats])\n",
    "df3_scaled[floats] = scaled_columns\n",
    "\n",
    "df3_train = df3_scaled.loc[(df3_scaled.index < starting )].copy()\n",
    "df3_test = df3_scaled.loc[df3_scaled.index >= starting].copy()\n",
    "y_train = df3_train['actual'].copy()\n",
    "X_train = df3_train.drop('actual', 1).copy()\n",
    "y_test = df3_test['actual'].copy()\n",
    "X_test = df3_test.drop('actual', 1).copy()\n",
    "\n",
    "valid_results_3 = pd.read_csv(os.path.join(res_path, 'notebook_03/', str('model3_results_' + date + '.csv')), delimiter=';')\n",
    "test_results_3 = pd.read_csv(os.path.join(res_path, 'notebook_03/', str('model3_test_results' + date + '.csv')), delimiter=';')\n",
    "test_results_3 = test_results_3.sort_values('Mean absolute error', ascending=True)\n",
    "best_model_3 = test_results_3.loc[0]['Model name']\n",
    "\n",
    "config = valid_results_3.loc[valid_results_3['model_name'] == best_model_3]\n",
    "batch_size = int(config['batch_train'].values[0])\n",
    "size = int(y_test.shape[0] / batch_size)\n",
    "\n",
    "layers = literal_eval(config['config'].values[0])\n",
    "layers = layers['layers']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warnining: Division \"sample_size/batch_size\" not a natural number.\n",
      "Dropped the last 7 of 20711 number of obs.\n",
      "Effective validation split now is: 0.200\n",
      "Train on 16568 samples, validate on 4136 samples\n",
      "Epoch 1/25\n",
      "16568/16568 [==============================] - 11s - loss: 0.5338 - mean_absolute_error: 0.4890 - val_loss: 0.1999 - val_mean_absolute_error: 0.3639\n",
      "Epoch 2/25\n",
      "16568/16568 [==============================] - 10s - loss: 0.4044 - mean_absolute_error: 0.3975 - val_loss: 0.1748 - val_mean_absolute_error: 0.3390\n",
      "Epoch 3/25\n",
      "16568/16568 [==============================] - 10s - loss: 0.3823 - mean_absolute_error: 0.3754 - val_loss: 0.1836 - val_mean_absolute_error: 0.3502\n",
      "Epoch 4/25\n",
      "16568/16568 [==============================] - 10s - loss: 0.3663 - mean_absolute_error: 0.3644 - val_loss: 0.1998 - val_mean_absolute_error: 0.3674\n",
      "Epoch 5/25\n",
      "16568/16568 [==============================] - 10s - loss: 0.3596 - mean_absolute_error: 0.3590 - val_loss: 0.2073 - val_mean_absolute_error: 0.3774\n",
      "Epoch 00004: early stopping\n"
     ]
    }
   ],
   "source": [
    "batch_size = 8\n",
    "model3 = lstm.create_model(layers=layers, sample_size=X_train.shape[0], batch_size=batch_size, timesteps=1, \n",
    "                           features=X_train.shape[1], loss='mse', optimizer='adam')\n",
    "history = lstm.train_model(model=model3, mode='fit', y=y_train, X=X_train, \n",
    "                           batch_size=batch_size, timesteps=1, epochs=25, \n",
    "                           rearrange=False, validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 8/24 [=========>....................] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "starting_loc = starting\n",
    "starting_utc = starting.astimezone(pytz.utc)\n",
    "ending_utc = df3_test.tail(1).index[0]\n",
    "ending_loc = ending_utc.tz_convert('Europe/Zurich')\n",
    "day_changes = pd.date_range(start=starting_loc, end=ending_loc, freq='24h', tz=\"Europe/Zurich\")\n",
    "\n",
    "predictions = pd.DataFrame(index=pd.date_range(start=starting_loc, end=ending_loc, normalize=True, freq='60min', tz='Europe/Zurich'))\n",
    "predictions.index = predictions.index.tz_convert('utc')\n",
    "\n",
    "for idx, hour in enumerate(day_changes):\n",
    "    if idx == 0:\n",
    "        pass\n",
    "    else:\n",
    "        dh = df3_test.loc[(df3_test.index >= hour - pd.DateOffset(days=1)) & (df3_test.index < hour)]\n",
    "        y_train = dh['actual']\n",
    "        X_train = dh.drop('actual', 1)\n",
    "        history = lstm.train_model(model=model3, mode='fit', y=y_train, X=X_train, \n",
    "                                   batch_size=batch_size, timesteps=1, epochs=100, rearrange=False, validation_split=0,\n",
    "                                   verbose=0, early_stopping=False)\n",
    "    \n",
    "    df = df3_test.loc[(df3_test.index >= hour) & (df3_test.index < hour + pd.DateOffset(days=2))]\n",
    "    df = df.drop('actual', 1)\n",
    "    X_predict = df\n",
    "    scaled_predictions = lstm.get_predictions(model=model3, X=X_predict, batch_size=batch_size, timesteps=1, verbose=1)\n",
    "    hour_utc = hour.tz_convert('utc')\n",
    "    window = pd.date_range(start=hour_utc, periods=len(scaled_predictions), freq='60min', tz='UTC')\n",
    "    result = pd.DataFrame(data={\"model3\": scaled_predictions.flatten()}, index=window)\n",
    "    predictions = predictions.combine_first(result)\n",
    "\n",
    "mu = scaler.mean_[0]\n",
    "sigma = scaler.scale_[0]\n",
    "model3_predictions = mu + sigma*predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----------+---------------+\n",
      "|      |    entsoe |   m3-calendar |\n",
      "+======+===========+===============+\n",
      "| MSE  | 14018.062 |     84382.357 |\n",
      "+------+-----------+---------------+\n",
      "| MAE  |    77.729 |       229.974 |\n",
      "+------+-----------+---------------+\n",
      "| MAPE |     1.100 |         3.395 |\n",
      "+------+-----------+---------------+\n"
     ]
    }
   ],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "dfc = data.load_dataset(path=path, modules=['actual', 'entsoe'])\n",
    "forecasts = model3_predictions\n",
    "forecasts = forecasts.join(dfc)\n",
    "forecasts = forecasts.dropna()\n",
    "results = {}\n",
    "results[''] = ['MSE', 'MAE', 'MAPE']\n",
    "results['entsoe'] = [mean_squared_error(forecasts['actual'], forecasts['entsoe']), \n",
    "                     mean_absolute_error(forecasts['actual'], forecasts['entsoe']),\n",
    "                     mean_absolute_percentage_error(forecasts['actual'], forecasts['entsoe'])\n",
    "                    ]\n",
    "results['m3-calendar'] = [mean_squared_error(forecasts['actual'], forecasts['model3']), \n",
    "                          mean_absolute_error(forecasts['actual'], forecasts['model3']),\n",
    "                          mean_absolute_percentage_error(forecasts['actual'], forecasts['model3'])\n",
    "                         ]\n",
    "\n",
    "print(tabulate(results, headers='keys', numalign=\"right\", tablefmt='grid', floatfmt=\".3f\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib\n",
    "plt.figure()\n",
    "plt.plot(forecasts.index, forecasts['entsoe'], label='ENTSOE Forecast')\n",
    "plt.plot(forecasts.index, forecasts['actual'], label='Actual Load')\n",
    "plt.plot(forecasts.index, forecasts['model3'], label='Model 3 (Calendar)')\n",
    "plt.title('Forecast Comparison: Rolling Forecast')\n",
    "plt.ylabel('Electricity load (in MW)')\n",
    "plt.xlabel('Date')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "import tensorflow as tf\n",
    "tf.reset_default_graph()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
