{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Forecasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: TkAgg\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from keras.models import load_model\n",
    "from keras import backend as K\n",
    "\n",
    "import pytz\n",
    "\n",
    "# Setup for Latex Export: https://matplotlib.org/users/pgf.html. Need to import before pyplot\n",
    "def figsize(scale):\n",
    "    fig_width_pt = 469.755                          # Get this from LaTeX using \\the\\textwidth\n",
    "    inches_per_pt = 1.0/72.27                       # Convert pt to inch\n",
    "    golden_mean = (np.sqrt(5.0)-1.0)/2.0            # Aesthetic ratio (you could change this)\n",
    "    fig_width = fig_width_pt*inches_per_pt*scale    # width in inches\n",
    "    fig_height = fig_width*golden_mean              # height in inches\n",
    "    fig_size = [fig_width,fig_height]\n",
    "    return fig_size\n",
    "\n",
    "import matplotlib as mpl\n",
    "mpl.use('pgf')\n",
    "pgf_with_rc_fonts = {\n",
    "    \"text.usetex\": True,\n",
    "    \"font.family\": \"serif\",\n",
    "    \"axes.labelsize\": 10,               # LaTeX default is 10pt font.\n",
    "    \"font.size\": 10,\n",
    "    \"legend.fontsize\": 8,               # Make the legend/label fonts a little smaller\n",
    "    \"xtick.labelsize\": 8,\n",
    "    \"ytick.labelsize\": 8,\n",
    "    \"figure.figsize\": figsize(0.9),     # default fig size of 0.9 textwidth\n",
    "    #\"font.serif\": [],                   # use latex default serif font\n",
    "    #\"font.sans-serif\": [\"DejaVu Sans\"], # use a specific sans-serif font\n",
    "}\n",
    "mpl.rcParams.update(pgf_with_rc_fonts)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Import custom module functions\n",
    "module_path = os.path.abspath(os.path.join('../'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from lstm_load_forecasting import data, lstm\n",
    "\n",
    "from ast import literal_eval\n",
    "\n",
    "%matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TBATS Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tbats_fc = pd.read_csv(os.path.join('../Data', 'tbats_forecast_01022017-h5000.csv'))\n",
    "\n",
    "starting = datetime.datetime(2017,2,1,0,0,0,0, tzinfo=pytz.utc )\n",
    "forecasts = pd.DataFrame(data={\"tbats_forecast\": tbats_fc['tbats_fc'].values}, index=pd.date_range(starting, periods=5000, freq='60min'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ARMA Forecast 1: ENTSOE + Calendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arma_fc = pd.read_csv(os.path.join('../Data', 'arma_fc.csv'))\n",
    "starting = datetime.datetime(2017,2,1,0,0,0,0, tzinfo=pytz.utc)\n",
    "arma_forecasts = pd.DataFrame(data={\"arma_forecast\": arma_fc['x'].values}, index=pd.date_range(starting, periods=arma_fc.shape[0], freq='60min'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ARMA Forecast 2: Weather + Calendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "arma_fc2 = pd.read_csv(os.path.join('../Data', 'arma_fc2.csv'))\n",
    "starting = datetime.datetime(2017,2,1,0,0,0,0, tzinfo=pytz.utc)\n",
    "arma_forecasts2 = pd.DataFrame(data={\"arma_forecast2\": arma_fc2['x'].values}, index=pd.date_range(starting, periods=arma_fc2.shape[0], freq='60min'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actual Load and ENTSOE Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv(os.path.join('Data', 'fulldataset.csv'), sep=';', usecols=[0,1,2], parse_dates=[0], index_col = 0)\n",
    "path = os.path.join('../Data', 'fulldataset.csv')\n",
    "entsoe = data.load_dataset(path=path, modules=['entsoe'])\n",
    "actual = data.load_dataset(path=path, modules=['actual'])\n",
    "\n",
    "forecasts = forecasts.join(entsoe)\n",
    "forecasts = forecasts.join(actual)\n",
    "forecasts = forecasts.join(arma_forecasts)\n",
    "forecasts = forecasts.join(arma_forecasts2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best models based on test results\n",
    "res_path = os.path.abspath('../results/')\n",
    "model_dir = os.path.abspath('../models/')\n",
    "date = '20170616'\n",
    "starting = datetime.datetime(2017,2,1,0,0,0,0, tzinfo=pytz.utc )\n",
    "epochs = 20\n",
    "retrain = False\n",
    "min_delta = 0.006\n",
    "patience = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 4 (ENTSO-E + Calendar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2424/2512 [===========================>..] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "model_id = 4\n",
    "\n",
    "df4 = data.load_dataset(path=path, modules=['actual', 'entsoe', 'calendar'])\n",
    "df4_scaled = df4.copy()\n",
    "df4_scaled = df4_scaled.dropna()\n",
    "\n",
    "# Get all float type columns\n",
    "floats = [key for key in dict(df4_scaled.dtypes) if dict(df4_scaled.dtypes)[key] in ['float64']]\n",
    "scaler = StandardScaler()\n",
    "scaled_columns = scaler.fit_transform(df4_scaled[floats])\n",
    "df4_scaled[floats] = scaled_columns\n",
    "\n",
    "df4_train = df4_scaled.loc[(df4_scaled.index < starting)].copy()\n",
    "df4_test = df4_scaled.loc[df4_scaled.index >= starting].copy()\n",
    "y_train = df4_train['actual'].copy()\n",
    "X_train = df4_train.drop('actual', 1).copy()\n",
    "y_test = df4_test['actual'].copy()\n",
    "X_test = df4_test.drop('actual', 1).copy()\n",
    "\n",
    "valid_results_4 = pd.read_csv(os.path.join(res_path, 'notebook_04/', str('04_results_' + date + '.csv')), delimiter=';')\n",
    "test_results_4 = pd.read_csv(os.path.join(res_path, 'notebook_04/', str('04_test_results' + date + '.csv')), delimiter=';')\n",
    "test_results_4 = test_results_4.sort_values('Mean absolute error', ascending=True)\n",
    "best_model_4 = test_results_4.loc[0]['Model name']\n",
    "\n",
    "config = valid_results_4.loc[valid_results_4['model_name'] == best_model_4]\n",
    "batch_size = int(config['batch_train'].values[0])\n",
    "size = int(y_test.shape[0] / batch_size)\n",
    "\n",
    "# If manually want to retrain model with different settings\n",
    "if retrain:\n",
    "    layers = literal_eval(config['config'].values[0])\n",
    "    layers = layers['layers']\n",
    "\n",
    "    model4 = lstm.create_model(layers=layers, sample_size=X_train.shape[0], \n",
    "                               batch_size=config['batch_train'].values, timesteps=1, \n",
    "                               features=X_train.shape[1], loss='mse', optimizer='adam')\n",
    "    history = lstm.train_model(model=model4, mode='fit', y=y_train, X=X_train, \n",
    "                           batch_size=batch_size, timesteps=1, epochs=epochs, \n",
    "                           rearrange=False, validation_split=0.2, verbose=1,\n",
    "                           early_stopping=False\n",
    "                         )\n",
    "# Load trained model\n",
    "elif not retrain:\n",
    "    notebook = 'notebook_0' + str(model_id)\n",
    "    mod_name = config['model_name'].values[0]\n",
    "    filename = os.path.join(model_dir, notebook, (mod_name +'.h5'))\n",
    "    model4 = load_model(filename)\n",
    "    model4.reset_states()\n",
    "    \n",
    "scaled_predictions = lstm.get_predictions(model=model4, X=X_test[0:size*batch_size], batch_size=batch_size, timesteps=1, verbose=1)\n",
    "\n",
    "mu = scaler.mean_[0]\n",
    "sigma = scaler.scale_[0]\n",
    "\n",
    "mod4_predictions = mu + sigma*scaled_predictions\n",
    "df_mod4 = pd.DataFrame(data={\"model4\": mod4_predictions.flatten()}, index=pd.date_range(starting, periods=mod4_predictions.shape[0], freq='60min'))\n",
    "if 'model4' in forecasts.columns:\n",
    "    forecasts = forecasts.drop('model4', 1)\n",
    "forecasts = forecasts.join(df_mod4)\n",
    "\n",
    "K.clear_session()\n",
    "import tensorflow as tf\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 5 (Calendar + Weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2400/2512 [===========================>..] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "model_id = 5\n",
    "\n",
    "df5 = data.load_dataset(path=path, modules=['actual', 'calendar', 'weather'])\n",
    "df5_scaled = df5.copy()\n",
    "df5_scaled = df5_scaled.dropna()\n",
    "\n",
    "# Get all float type columns\n",
    "floats = [key for key in dict(df5_scaled.dtypes) if dict(df5_scaled.dtypes)[key] in ['float64']]\n",
    "scaler = StandardScaler()\n",
    "scaled_columns = scaler.fit_transform(df5_scaled[floats])\n",
    "df5_scaled[floats] = scaled_columns\n",
    "\n",
    "df5_train = df5_scaled.loc[(df5_scaled.index < starting)].copy()\n",
    "df5_test = df5_scaled.loc[df5_scaled.index >= starting].copy()\n",
    "y_train = df5_train['actual'].copy()\n",
    "X_train = df5_train.drop('actual', 1).copy()\n",
    "y_test = df5_test['actual'].copy()\n",
    "X_test = df5_test.drop('actual', 1).copy()\n",
    "\n",
    "valid_results_5 = pd.read_csv(os.path.join(res_path, 'notebook_05/', str('05_results_' + date + '.csv')), delimiter=';')\n",
    "test_results_5 = pd.read_csv(os.path.join(res_path, 'notebook_05/', str('05_test_results' + date + '.csv')), delimiter=';')\n",
    "test_results_5 = test_results_5.sort_values('Mean absolute error', ascending=True)\n",
    "best_model_5 = test_results_5.loc[0]['Model name']\n",
    "\n",
    "config = valid_results_5.loc[valid_results_5['model_name'] == best_model_5]\n",
    "batch_size = int(config['batch_train'].values[0])\n",
    "size = int(y_test.shape[0] / batch_size)\n",
    "\n",
    "# If manually want to retrain model with different settings\n",
    "if retrain:\n",
    "    layers = literal_eval(config['config'].values[0])\n",
    "    layers = layers['layers']\n",
    "\n",
    "    model5 = lstm.create_model(layers=layers, sample_size=X_train.shape[0], \n",
    "                               batch_size=config['batch_train'].values, timesteps=1, \n",
    "                               features=X_train.shape[1], loss='mse', optimizer='adam')\n",
    "    history = lstm.train_model(model=model5, mode='fit', y=y_train, X=X_train, \n",
    "                           batch_size=batch_size, timesteps=1, epochs=epochs, \n",
    "                           rearrange=False, validation_split=0.2, verbose=1,\n",
    "                           early_stopping=False\n",
    "                         )\n",
    "# Load trained model\n",
    "elif not retrain:\n",
    "    notebook = 'notebook_0' + str(model_id)\n",
    "    mod_name = config['model_name'].values[0]\n",
    "    filename = os.path.join(model_dir, notebook, (mod_name +'.h5'))\n",
    "    model5 = load_model(filename)\n",
    "    model5.reset_states()\n",
    "    \n",
    "scaled_predictions = lstm.get_predictions(model=model5, X=X_test[0:size*batch_size], batch_size=batch_size, timesteps=1, verbose=1)\n",
    "\n",
    "mu = scaler.mean_[0]\n",
    "sigma = scaler.scale_[0]\n",
    "\n",
    "mod5_predictions = mu + sigma*scaled_predictions\n",
    "df_mod5 = pd.DataFrame(data={\"model5\": mod5_predictions.flatten()}, index=pd.date_range(starting, periods=mod5_predictions.shape[0], freq='60min'))\n",
    "if 'model5' in forecasts.columns:\n",
    "    forecasts = forecasts.drop('model5', 1)\n",
    "forecasts = forecasts.join(df_mod5)\n",
    "\n",
    "K.clear_session()\n",
    "import tensorflow as tf\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM Model 6 (All available data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2400/2512 [===========================>..] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "model_id = 6\n",
    "\n",
    "df6 = data.load_dataset(path=path, modules=['all'])\n",
    "df6_scaled = df6.copy()\n",
    "df6_scaled = df6_scaled.dropna()\n",
    "\n",
    "# Get all float type columns\n",
    "floats = [key for key in dict(df6_scaled.dtypes) if dict(df6_scaled.dtypes)[key] in ['float64']]\n",
    "scaler = StandardScaler()\n",
    "scaled_columns = scaler.fit_transform(df6_scaled[floats])\n",
    "df6_scaled[floats] = scaled_columns\n",
    "\n",
    "df6_train = df6_scaled.loc[(df6_scaled.index < starting)].copy()\n",
    "df6_test = df6_scaled.loc[df6_scaled.index >= starting].copy()\n",
    "y_train = df6_train['actual'].copy()\n",
    "X_train = df6_train.drop('actual', 1).copy()\n",
    "y_test = df6_test['actual'].copy()\n",
    "X_test = df6_test.drop('actual', 1).copy()\n",
    "\n",
    "valid_results_6 = pd.read_csv(os.path.join(res_path, 'notebook_06/', str('06_results_' + date + '.csv')), delimiter=';')\n",
    "test_results_6 = pd.read_csv(os.path.join(res_path, 'notebook_06/', str('06_test_results' + date + '.csv')), delimiter=';')\n",
    "test_results_6 = test_results_6.sort_values('Mean absolute error', ascending=True)\n",
    "best_model_6 = test_results_6.loc[0]['Model name']\n",
    "\n",
    "config = valid_results_6.loc[valid_results_6['model_name'] == best_model_6]\n",
    "batch_size = int(config['batch_train'].values[0])\n",
    "size = int(y_test.shape[0] / batch_size)\n",
    "\n",
    "# If manually want to retrain model with different settings\n",
    "if retrain:\n",
    "    layers = literal_eval(config['config'].values[0])\n",
    "    layers = layers['layers']\n",
    "\n",
    "    model6 = lstm.create_model(layers=layers, sample_size=X_train.shape[0], \n",
    "                               batch_size=config['batch_train'].values, timesteps=1, \n",
    "                               features=X_train.shape[1], loss='mse', optimizer='adam')\n",
    "    history = lstm.train_model(model=model6, mode='fit', y=y_train, X=X_train, \n",
    "                           batch_size=batch_size, timesteps=1, epochs=epochs, \n",
    "                           rearrange=False, validation_split=0.2, verbose=1,\n",
    "                           early_stopping=False\n",
    "                         )\n",
    "# Load trained model\n",
    "elif not retrain:\n",
    "    notebook = 'notebook_0' + str(model_id)\n",
    "    mod_name = config['model_name'].values[0]\n",
    "    filename = os.path.join(model_dir, notebook, (mod_name +'.h5'))\n",
    "    model6 = load_model(filename)\n",
    "    model6.reset_states()\n",
    "    \n",
    "scaled_predictions = lstm.get_predictions(model=model6, X=X_test[0:size*batch_size], batch_size=batch_size, timesteps=1, verbose=1)\n",
    "\n",
    "mu = scaler.mean_[0]\n",
    "sigma = scaler.scale_[0]\n",
    "\n",
    "mod6_predictions = mu + sigma*scaled_predictions\n",
    "df_mod6 = pd.DataFrame(data={\"model6\": mod6_predictions.flatten()}, index=pd.date_range(starting, periods=mod6_predictions.shape[0], freq='60min'))\n",
    "if 'model6' in forecasts.columns:\n",
    "    forecasts = forecasts.drop('model6', 1)\n",
    "forecasts = forecasts.join(df_mod6)\n",
    "\n",
    "K.clear_session()\n",
    "import tensorflow as tf\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table with Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrrr}\n",
      "\\toprule\n",
      "      &   entsoe &    tbats &    arima &   arima2 &   m4-entsoe-cal &   m5-cal-weather &   m6-all \\\\\n",
      "\\midrule\n",
      " MSE  & 427415.1 & 994304.1 & 398569.0 & 494220.7 &        175988.0 &         162298.2 & 180442.3 \\\\\n",
      " MAE  &    518.3 &    841.7 &    495.9 &    562.9 &           335.0 &            311.4 &    336.7 \\\\\n",
      " MAPE &      7.7 &     13.0 &      7.7 &      8.6 &             5.0 &              4.7 &      5.1 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "         entsoe      tbats      arima     arima2    m4-entsoe-cal    m5-cal-weather     m6-all\n",
      "----  ---------  ---------  ---------  ---------  ---------------  ----------------  ---------\n",
      "MSE   427415.12  994304.13  398569.04  494220.71        175987.98         162298.21  180442.25\n",
      "MAE      518.27     841.72     495.88     562.88           334.96            311.43     336.68\n",
      "MAPE       7.69      13.00       7.69       8.63             5.05              4.67       5.12\n"
     ]
    }
   ],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "forecasts = forecasts.dropna()\n",
    "\n",
    "results = {}\n",
    "results[''] = ['MSE', 'MAE', 'MAPE']\n",
    "results['entsoe'] = [mean_squared_error(forecasts['actual'], forecasts['entsoe']), \n",
    "                     mean_absolute_error(forecasts['actual'], forecasts['entsoe']),\n",
    "                     mean_absolute_percentage_error(forecasts['actual'], forecasts['entsoe'])\n",
    "                    ]\n",
    "results['tbats'] = [mean_squared_error(forecasts['actual'], forecasts['tbats_forecast']), \n",
    "                    mean_absolute_error(forecasts['actual'], forecasts['tbats_forecast']),\n",
    "                    mean_absolute_percentage_error(forecasts['actual'], forecasts['tbats_forecast'])\n",
    "                   ]\n",
    "results['arima'] = [mean_squared_error(forecasts['actual'], forecasts['arma_forecast']), \n",
    "                    mean_absolute_error(forecasts['actual'], forecasts['arma_forecast']),\n",
    "                    mean_absolute_percentage_error(forecasts['actual'], forecasts['arma_forecast'])\n",
    "                   ]\n",
    "results['arima2'] = [mean_squared_error(forecasts['actual'], forecasts['arma_forecast2']), \n",
    "                    mean_absolute_error(forecasts['actual'], forecasts['arma_forecast2']),\n",
    "                    mean_absolute_percentage_error(forecasts['actual'], forecasts['arma_forecast2'])\n",
    "                   ]\n",
    "results['m4-entsoe-cal'] = [mean_squared_error(forecasts['actual'], forecasts['model4']), \n",
    "                          mean_absolute_error(forecasts['actual'], forecasts['model4']),\n",
    "                          mean_absolute_percentage_error(forecasts['actual'], forecasts['model4'])\n",
    "                         ]\n",
    "results['m5-cal-weather'] = [mean_squared_error(forecasts['actual'], forecasts['model5']), \n",
    "                          mean_absolute_error(forecasts['actual'], forecasts['model5']),\n",
    "                          mean_absolute_percentage_error(forecasts['actual'], forecasts['model5'])\n",
    "                         ]\n",
    "results['m6-all'] = [mean_squared_error(forecasts['actual'], forecasts['model6']), \n",
    "                     mean_absolute_error(forecasts['actual'], forecasts['model6']),\n",
    "                     mean_absolute_percentage_error(forecasts['actual'], forecasts['model6'])\n",
    "                    ]\n",
    "print(tabulate(results, headers='keys', numalign=\"right\", tablefmt='latex_booktabs', floatfmt=\".1f\"))\n",
    "print(tabulate(results, headers='keys', numalign=\"right\", floatfmt=\".2f\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%matplotlib qt\n",
    "#plt.clf()\n",
    "#plt.ion()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(forecasts.index, forecasts['entsoe'], label='ENTSOE Forecast')\n",
    "plt.plot(forecasts.index, forecasts['actual'], label='Actual Load')\n",
    "#plt.plot(forecasts.index, forecasts['tbats_forecast'], label='TBATS Forecast')\n",
    "#plt.plot(forecasts.index, forecasts['arma_forecast'], label='ARIMA Forecast')\n",
    "#plt.plot(forecasts.index, forecasts['model4'], label='Model 4 (ENTSO-E & Calendar)')\n",
    "plt.plot(forecasts.index, forecasts['model5'], label='Model 5 (Calendar & Weather)')\n",
    "#plt.plot(forecasts.index, forecasts['model6'], label='Model 6 (All)')\n",
    "plt.title('Forecast Comparison: Test Data')\n",
    "plt.ylabel('Electricity load (in MW)')\n",
    "plt.xlabel('Date')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show\n",
    "\n",
    "#filename = plot_dir + model_name + 'top_model_predictions'\n",
    "#plt.savefig(filename + '.pgf')\n",
    "#plt.savefig(filename + '.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
